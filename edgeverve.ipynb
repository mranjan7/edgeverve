{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Total time to run the solution file is around 80 min.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import time\n",
    "import Levenshtein\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import gc\n",
    "\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please change the paths as per your local configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"../input/edgeverve2/\"\n",
    "output_path = \"\"\n",
    "kera_model_path = \"../input/kera-model/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(input_path+\"sample_submission.csv\")\n",
    "train_df = pd.read_csv(input_path+\"Train.csv\")\n",
    "test_df = pd.read_csv(input_path+\"Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5566 entries, 0 to 5565\n",
      "Data columns (total 6 columns):\n",
      "Inv_Id              5566 non-null int64\n",
      "Vendor_Code         5566 non-null object\n",
      "GL_Code             5566 non-null object\n",
      "Inv_Amt             5566 non-null float64\n",
      "Item_Description    5566 non-null object\n",
      "Product_Category    5566 non-null object\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 261.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inv_Id</th>\n",
       "      <th>Vendor_Code</th>\n",
       "      <th>GL_Code</th>\n",
       "      <th>Inv_Amt</th>\n",
       "      <th>Item_Description</th>\n",
       "      <th>Product_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15001</td>\n",
       "      <td>VENDOR-1676</td>\n",
       "      <td>GL-6100410</td>\n",
       "      <td>83.24</td>\n",
       "      <td>Artworking/Typesetting Production Jun 2009 Champion Parts Inc SMAP Prototype and Comp Production/Packaging Design</td>\n",
       "      <td>CLASS-1963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15002</td>\n",
       "      <td>VENDOR-1883</td>\n",
       "      <td>GL-2182000</td>\n",
       "      <td>51.18</td>\n",
       "      <td>Auto Leasing Corporate Services Corning Inc /Ny 2013-Mar  Auto Leasing and Maintenance Other Corporate Services</td>\n",
       "      <td>CLASS-1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15004</td>\n",
       "      <td>VENDOR-1999</td>\n",
       "      <td>GL-6050100</td>\n",
       "      <td>79.02</td>\n",
       "      <td>Store Management Lease/Rent Deltona Corp Real Estate Base Rent Jul2018</td>\n",
       "      <td>CLASS-1274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15005</td>\n",
       "      <td>VENDOR-1771</td>\n",
       "      <td>GL-6101400</td>\n",
       "      <td>48.50</td>\n",
       "      <td>Store Construction General Requirements Colonial Trust Iii General Contractor Final Site Clean Up 2005-Dec</td>\n",
       "      <td>CLASS-1522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15006</td>\n",
       "      <td>VENDOR-1331</td>\n",
       "      <td>GL-2182000</td>\n",
       "      <td>63.35</td>\n",
       "      <td>Jul 2015 Aydin Corp Contingent Labor/Temp Labor Contingent Labor/Temp Labor Corporate Services Human Resources</td>\n",
       "      <td>CLASS-1376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Inv_Id       ...        Product_Category\n",
       "0   15001       ...              CLASS-1963\n",
       "1   15002       ...              CLASS-1250\n",
       "2   15004       ...              CLASS-1274\n",
       "3   15005       ...              CLASS-1522\n",
       "4   15006       ...              CLASS-1376\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inv_Id</th>\n",
       "      <th>Vendor_Code</th>\n",
       "      <th>GL_Code</th>\n",
       "      <th>Inv_Amt</th>\n",
       "      <th>Item_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15003</td>\n",
       "      <td>VENDOR-2513</td>\n",
       "      <td>GL-6050310</td>\n",
       "      <td>56.13</td>\n",
       "      <td>Travel and Entertainment Miscellaneous Company Car (Field Only) Ground Transportation Miscellaneous Company Car (Field Only) Oct2011 Fortune National Corp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15008</td>\n",
       "      <td>VENDOR-1044</td>\n",
       "      <td>GL-6101400</td>\n",
       "      <td>96.56</td>\n",
       "      <td>Final Site Clean Up Store Construction Advanced Micro Devices Inc Oct2011 General Requirements General Contractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15013</td>\n",
       "      <td>VENDOR-1254</td>\n",
       "      <td>GL-6101400</td>\n",
       "      <td>55.93</td>\n",
       "      <td>Arabian American Development Co Final Site Clean Up 2008-Oct  General Requirements General Contractor Store Construction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15019</td>\n",
       "      <td>VENDOR-1331</td>\n",
       "      <td>GL-2182000</td>\n",
       "      <td>32.62</td>\n",
       "      <td>Corporate Services Contingent Labor/Temp Labor Human Resources Contingent Labor/Temp Labor Jun 2014 Aydin Corp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15020</td>\n",
       "      <td>VENDOR-2513</td>\n",
       "      <td>GL-6050310</td>\n",
       "      <td>25.81</td>\n",
       "      <td>Fortune National Corp Miscellaneous Company Car (Field Only) Jun-2015 Miscellaneous Company Car (Field Only) Ground Transportation Travel and Entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Inv_Id                                                                             ...                                                                                                                                                                                                                          Item_Description\n",
       "0   15003                                                                             ...                                                                                Travel and Entertainment Miscellaneous Company Car (Field Only) Ground Transportation Miscellaneous Company Car (Field Only) Oct2011 Fortune National Corp\n",
       "1   15008                                                                             ...                                                                                                                         Final Site Clean Up Store Construction Advanced Micro Devices Inc Oct2011 General Requirements General Contractor\n",
       "2   15013                                                                             ...                                                                                                                  Arabian American Development Co Final Site Clean Up 2008-Oct  General Requirements General Contractor Store Construction\n",
       "3   15019                                                                             ...                                                                                                                            Corporate Services Contingent Labor/Temp Labor Human Resources Contingent Labor/Temp Labor Jun 2014 Aydin Corp\n",
       "4   15020                                                                             ...                                                                               Fortune National Corp Miscellaneous Company Car (Field Only) Jun-2015 Miscellaneous Company Car (Field Only) Ground Transportation Travel and Entertainment\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inv_Id</th>\n",
       "      <th>Product_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CLASS-784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CLASS-784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CLASS-784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CLASS-784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CLASS-784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Inv_Id Product_Category\n",
       "0       1        CLASS-784\n",
       "1       2        CLASS-784\n",
       "2       3        CLASS-784\n",
       "3       4        CLASS-784\n",
       "4       5        CLASS-784"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size  (5566, 6)\n",
      "test size  (2446, 5)\n",
      "test train ratio :  0.43945382680560546\n"
     ]
    }
   ],
   "source": [
    "print('train size ',train_df.shape)\n",
    "print('test size ',test_df.shape)\n",
    "print('test train ratio : ',(test_df.shape[0]/train_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_list(l):\n",
    "    ulist = []\n",
    "    [ulist.append(x) for x in l if x not in ulist]\n",
    "    return ulist\n",
    "def count_chars(x):\n",
    "        n_l = 0 # count letters\n",
    "        n_n = 0 # count numbers\n",
    "        n_s = 0 # count symbols\n",
    "        n_ul = 0 # count upper letters\n",
    "        n_ll = 0 # count lower letters\n",
    "        for i in range(0, len(x)):\n",
    "            if x[i].isalpha():\n",
    "                n_l += 1\n",
    "                if x[i].isupper():\n",
    "                    n_ul += 1\n",
    "                elif x[i].islower():\n",
    "                    n_ll += 1\n",
    "            elif x[i].isdigit():\n",
    "                n_n += 1\n",
    "            else:\n",
    "                n_s += 1\n",
    "\n",
    "        return pd.Series([n_l, n_n, n_s, n_ul, n_ll])\n",
    "def strstat(x):\n",
    "    r = np.array([ord(c) for c in x])\n",
    "    return pd.Series([\n",
    "        np.sum(r), \n",
    "        np.mean(r), \n",
    "        np.std(r), \n",
    "        np.min(r), \n",
    "        np.max(r),\n",
    "        skew(r), \n",
    "        kurtosis(r),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "def process_for_features(df):\n",
    "    cols = ['n_l', 'n_n', 'n_s', 'n_ul', 'n_ll']\n",
    "    for c in cols:\n",
    "        df[c] = 0\n",
    "    tqdm.pandas(desc='count_chars')\n",
    "    df[cols] = df['Item_Description'].progress_apply(lambda x: count_chars(x))\n",
    "    df['Vendor_gl-code'] = df[['Vendor_Code','GL_Code']].apply(lambda x : ''.join(x),axis = 1)\n",
    "    le.fit(df['Vendor_gl-code'])\n",
    "    df['Vendor_gl-code'] = le.transform(df['Vendor_gl-code'])\n",
    "    le.fit(df['Vendor_Code'])\n",
    "    df['Vendor_Code'] = le.transform(df['Vendor_Code'])\n",
    "    le.fit(df['GL_Code'])\n",
    "    df['GL_Code'] = le.transform(df['GL_Code'])\n",
    "    #Making the product category as int\n",
    "    df.Product_Category = df.Product_Category.str[6:]\n",
    "    df[\"Product_Category\"] = pd.to_numeric(df[\"Product_Category\"],errors = \"coerce\")\n",
    "    #Getting some new features\n",
    "    gb = df.groupby(['Vendor_Code'],as_index = False).agg({'Inv_Amt':{'Vendor_code_sum':'sum'}})\n",
    "    gb.columns = [col[0] if col[-1] == '' else col[-1] for col in gb.columns.values]\n",
    "    df = pd.merge(df,gb,on ='Vendor_Code',how = 'left').fillna(0)\n",
    "    gb = df.groupby(['GL_Code'],as_index = False).agg({'Inv_Amt':{'GL_Code_sum':'sum'}})\n",
    "    gb.columns = [col[0] if col[-1] == '' else col[-1] for col in gb.columns.values]\n",
    "    df = pd.merge(df,gb,on ='GL_Code',how = 'left').fillna(0)\n",
    "    gb = df.groupby(['Vendor_Code'],as_index = False).agg({'Inv_Amt':{'Vendor_code_mean':'mean'}})\n",
    "    gb.columns = [col[0] if col[-1] == '' else col[-1] for col in gb.columns.values]\n",
    "    df = pd.merge(df,gb,on ='Vendor_Code',how = 'left').fillna(0)\n",
    "    gb = df.groupby(['GL_Code'],as_index = False).agg({'Inv_Amt':{'GL_Code_mean':'mean'}})\n",
    "    gb.columns = [col[0] if col[-1] == '' else col[-1] for col in gb.columns.values]\n",
    "    df = pd.merge(df,gb,on ='GL_Code',how = 'left').fillna(0)\n",
    "    gb = df.groupby(['Vendor_Code'],as_index = False).agg({'Product_Category':{'Vendor_code_pc_mean':'mean'}})\n",
    "    gb.columns = [col[0] if col[-1] == '' else col[-1] for col in gb.columns.values]\n",
    "    df = pd.merge(df,gb,on ='Vendor_Code',how = 'left').fillna(0)\n",
    "    gb = df.groupby(['GL_Code'],as_index = False).agg({'Product_Category':{'GL_Code_pc_mean':'mean'}})\n",
    "    gb.columns = [col[0] if col[-1] == '' else col[-1] for col in gb.columns.values]\n",
    "    df = pd.merge(df,gb,on ='GL_Code',how = 'left').fillna(0)\n",
    "    gb = df.groupby(['Vendor_Code'],as_index = False).agg({'Product_Category':{'Vendor_code_pc_sum':'sum'}})\n",
    "    gb.columns = [col[0] if col[-1] == '' else col[-1] for col in gb.columns.values]\n",
    "    df = pd.merge(df,gb,on ='Vendor_Code',how = 'left').fillna(0)\n",
    "    gb = df.groupby(['GL_Code'],as_index = False).agg({'Product_Category':{'GL_Code_pc_sum':'sum'}})\n",
    "    gb.columns = [col[0] if col[-1] == '' else col[-1] for col in gb.columns.values]\n",
    "    df = pd.merge(df,gb,on ='GL_Code',how = 'left').fillna(0)\n",
    "    cumsum = df.groupby(['GL_Code'])['Product_Category'].cumsum() - df['Product_Category']\n",
    "    cumcnt = df.groupby(['GL_Code']).cumcount()\n",
    "    df['GL_Code_mean_target'] = cumsum/cumcnt\n",
    "    cumsum = df.groupby(['Vendor_Code'])['Product_Category'].cumsum() - df['Product_Category']\n",
    "    cumcnt = df.groupby(['Vendor_Code']).cumcount()\n",
    "    df['Vendor_Code_mean_target'] = cumsum/cumcnt\n",
    "    df = df.fillna(0)\n",
    "    #processing the item description field \n",
    "    df['Item_Description'] = df['Item_Description'].str.lower()\n",
    "    temp = []\n",
    "    for text in df['Item_Description']:\n",
    "        # Removing special characters and punctuations\n",
    "        text = re.sub(r'[?|!|\\'|\"|#]',r'',text)\n",
    "        text = re.sub(r'[.|,|)|(|\\|/]',r' ',text)\n",
    "        # Removing digits\n",
    "        text = re.sub(r'[0-9]',r' ',text) \n",
    "        # Removing months\n",
    "        text = re.sub('(\\s*)jan(\\s*)|(\\s*)feb(\\s*)|(\\s*)mar(\\s*)|(\\s*)apr(\\s*)|(\\s*)may(\\s*)|(\\s*)jun(\\s*)|(\\s*)jul(\\s*)|(\\s*)aug(\\s*)|(\\s*)sep(\\s*)|(\\s*)oct(\\s*)|(\\s*)nov(\\s*)|(\\s*)dec(\\s*)',' ',\n",
    "                      text)\n",
    "        temp.append(text)\n",
    "    df['Item_Description'] = temp\n",
    "    temp = []\n",
    "    for text in df['Item_Description']:\n",
    "        # Getting unique words in each sentence and sorting them and removing white spaces\n",
    "        text = str(sorted(' '.join(unique_list(text.split()))))\n",
    "        text = text.strip()\n",
    "        temp.append(text)\n",
    "    df['Item_Description_sorted'] = temp\n",
    "    cols = ['str_sum', 'str_mean', 'str_std', 'str_min', 'str_max', 'str_skew', 'str_kurtosis']\n",
    "    for c in cols:\n",
    "        df[c] = 0\n",
    "    tqdm.pandas(desc='strstat')\n",
    "    df[cols] = df['Item_Description'].progress_apply(lambda x: strstat(x))\n",
    "    df['nunique'] = df['Item_Description'].apply(lambda x : len(np.unique(x)))\n",
    "    tqdm.pandas(desc='distances')\n",
    "    #Getting new fature with Levenshtein distance\n",
    "    df['Levenshtein_distance'] = df['Item_Description'].progress_apply(lambda x: Levenshtein.distance(x, x[::-1]))\n",
    "    df['Levenshtein_distance_sorted'] = df['Item_Description_sorted'].progress_apply(lambda x: Levenshtein.distance(x, x[::-1]))\n",
    "    df['Levenshtein_ratio'] = df['Item_Description'].progress_apply(lambda x: Levenshtein.ratio(x, x[::-1]))\n",
    "    df['Levenshtein_ratio_sorted'] = df['Item_Description_sorted'].progress_apply(lambda x: Levenshtein.ratio(x, x[::-1]))\n",
    "    df['Levenshtein_jaro'] = df['Item_Description'].progress_apply(lambda x: Levenshtein.jaro(x, x[::-1]))\n",
    "    df['Levenshtein_jaro_sorted'] = df['Item_Description_sorted'].progress_apply(lambda x: Levenshtein.jaro(x, x[::-1]))\n",
    "    df['Levenshtein_hamming'] = df['Item_Description'].progress_apply(lambda x: Levenshtein.hamming(x, x[::-1]))\n",
    "    df['Levenshtein_hamming_sorted'] = df['Item_Description_sorted'].progress_apply(lambda x: Levenshtein.hamming(x, x[::-1]))\n",
    "    for m in range(1, 5):\n",
    "        df['Levenshtein_distance_m{}'.format(m)] = df['Item_Description'].progress_apply(lambda x: Levenshtein.distance(x[:-m], x[m:]))\n",
    "        df['Levenshtein_ratio_m{}'.format(m)] = df['Item_Description'].progress_apply(lambda x: Levenshtein.ratio(x[:-m], x[m:]))\n",
    "        df['Levenshtein_jaro_m{}'.format(m)] = df['Item_Description'].progress_apply(lambda x: Levenshtein.jaro(x[:-m], x[m:]))\n",
    "        df['Levenshtein_hamming_m{}'.format(m)] = df['Item_Description'].progress_apply(lambda x: Levenshtein.hamming(x[:-m], x[m:]))\n",
    "        df['Levenshtein_distance_m{}_sorted'.format(m)] = df['Item_Description_sorted'].progress_apply(lambda x: Levenshtein.distance(x[:-m], x[m:]))\n",
    "        df['Levenshtein_ratio_m{}_sorted'.format(m)] = df['Item_Description_sorted'].progress_apply(lambda x: Levenshtein.ratio(x[:-m], x[m:]))\n",
    "        df['Levenshtein_jaro_m{}_sorted'.format(m)] = df['Item_Description_sorted'].progress_apply(lambda x: Levenshtein.jaro(x[:-m], x[m:]))\n",
    "        df['Levenshtein_hamming_m{}_sorted'.format(m)] = df['Item_Description_sorted'].progress_apply(lambda x: Levenshtein.hamming(x[:-m], x[m:]))\n",
    "    #Getting new feature with TF IDF\n",
    "    tf_idf = TfidfVectorizer()\n",
    "    text_fitted = tf_idf.fit_transform(df['Item_Description'])\n",
    "    n = min(25,text_fitted.shape[1]-1)\n",
    "    svd = TruncatedSVD(n_components= n, n_iter=25, random_state=12)\n",
    "    truncated_tfidf = svd.fit_transform(text_fitted)\n",
    "    f_cols = ['f'+str(c) for c in range(n)]\n",
    "    all_columns = np.append(df.columns.values,f_cols)\n",
    "    int_cols = [c for c in df if df[c].dtype == 'int64']\n",
    "    float_cols = [c for c in df if df[c].dtype == 'float64']\n",
    "    df = np.hstack([df,truncated_tfidf])\n",
    "    df = pd.DataFrame(df,index = range(len(df)),columns = all_columns)\n",
    "    #Downcasting to reduce memory usage\n",
    "    df[int_cols] = df[int_cols].astype(np.int32)\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[f_cols] = df[f_cols].astype(np.float32)\n",
    "    x_columns = list(df.columns.values)\n",
    "    x_columns.remove('Inv_Id')\n",
    "    x_columns.remove('Item_Description')\n",
    "    x_columns.remove('Product_Category')\n",
    "    x_columns.remove('Item_Description_sorted')\n",
    "    y_column = ['Product_Category']\n",
    "    train = df[x_columns][:train_df.shape[0]:]\n",
    "    target = df[y_column][:train_df.shape[0]]\n",
    "    test = df[x_columns][train_df.shape[0]:]\n",
    "    x_train, x_val, y_train, y_val = train_test_split(train,target, test_size=0.4, random_state=42)\n",
    "    return x_train,x_val,y_train,y_val,test,train,target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.concat([train_df,test_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Validation split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "count_chars: 100%|██████████| 8012/8012 [00:02<00:00, 2811.69it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/pandas/core/groupby/groupby.py:4656: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n",
      "strstat: 100%|██████████| 8012/8012 [00:11<00:00, 728.16it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 31862.52it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:03<00:00, 2409.94it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 34796.69it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:03<00:00, 2612.19it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 83937.62it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:01<00:00, 4634.07it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 370186.21it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 329193.82it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 31993.35it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 34978.15it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 86510.10it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 364540.09it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:03<00:00, 2421.87it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:03<00:00, 2622.69it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:01<00:00, 4622.53it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 346551.62it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 33393.42it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 36142.86it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 87626.27it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 396016.40it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:03<00:00, 2427.03it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:03<00:00, 2641.65it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:01<00:00, 4662.74it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 323988.77it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 32752.45it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 36376.78it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 86810.24it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 400061.47it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:03<00:00, 2436.26it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:03<00:00, 2641.12it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:01<00:00, 4677.20it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 345138.59it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 33840.91it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 36527.95it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 86267.59it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 406665.02it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:03<00:00, 2463.10it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:02<00:00, 2672.35it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:01<00:00, 4717.81it/s]\n",
      "distances: 100%|██████████| 8012/8012 [00:00<00:00, 339335.80it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val,test,train,target = process_for_features(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "best_model = None\n",
    "best_pred = None\n",
    "bags = 10\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.992366 \n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=100,max_depth = 20, random_state=42)\n",
    "model_rf.fit(x_train,y_train)\n",
    "pred_val_rf = model_rf.predict(x_val)\n",
    "acc_score = accuracy_score(y_val, pred_val_rf)\n",
    "print(\"accuracy score %f \"%acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(model_rf.feature_importances_,index = \n",
    "                                   x_train.columns,columns=['importance']).sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f3</th>\n",
       "      <td>0.060416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2</th>\n",
       "      <td>0.048496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.047413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_hamming_m4</th>\n",
       "      <td>0.045913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_hamming_m2</th>\n",
       "      <td>0.040942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GL_Code_pc_mean</th>\n",
       "      <td>0.036268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GL_Code_mean_target</th>\n",
       "      <td>0.035888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>str_sum</th>\n",
       "      <td>0.034317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0</th>\n",
       "      <td>0.033891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GL_Code_sum</th>\n",
       "      <td>0.033805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GL_Code</th>\n",
       "      <td>0.027451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f5</th>\n",
       "      <td>0.027293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GL_Code_pc_sum</th>\n",
       "      <td>0.027022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f4</th>\n",
       "      <td>0.026515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_hamming_m1</th>\n",
       "      <td>0.026492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GL_Code_mean</th>\n",
       "      <td>0.026306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_hamming_m3</th>\n",
       "      <td>0.025779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_ll</th>\n",
       "      <td>0.023115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f12</th>\n",
       "      <td>0.021913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_l</th>\n",
       "      <td>0.020155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f6</th>\n",
       "      <td>0.020041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_ratio_m4</th>\n",
       "      <td>0.019150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f10</th>\n",
       "      <td>0.017291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_hamming</th>\n",
       "      <td>0.015374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f7</th>\n",
       "      <td>0.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f8</th>\n",
       "      <td>0.014254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_distance</th>\n",
       "      <td>0.013679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vendor_code_pc_sum</th>\n",
       "      <td>0.011357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vendor_code_sum</th>\n",
       "      <td>0.010904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_ul</th>\n",
       "      <td>0.010590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_ratio_m2</th>\n",
       "      <td>0.010060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f14</th>\n",
       "      <td>0.009954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f19</th>\n",
       "      <td>0.007444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f9</th>\n",
       "      <td>0.006753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f17</th>\n",
       "      <td>0.006700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_distance_sorted</th>\n",
       "      <td>0.006660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f11</th>\n",
       "      <td>0.006589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>str_max</th>\n",
       "      <td>0.005957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f18</th>\n",
       "      <td>0.005871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_jaro_m1_sorted</th>\n",
       "      <td>0.005754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f24</th>\n",
       "      <td>0.005473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_hamming_m2_sorted</th>\n",
       "      <td>0.005399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_hamming_m3_sorted</th>\n",
       "      <td>0.005353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f16</th>\n",
       "      <td>0.005309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_jaro_m2_sorted</th>\n",
       "      <td>0.005159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_ratio_m2_sorted</th>\n",
       "      <td>0.004913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_s</th>\n",
       "      <td>0.004810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f20</th>\n",
       "      <td>0.004798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_hamming_sorted</th>\n",
       "      <td>0.004641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f22</th>\n",
       "      <td>0.004594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_jaro_m3_sorted</th>\n",
       "      <td>0.004339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_ratio_sorted</th>\n",
       "      <td>0.004275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f13</th>\n",
       "      <td>0.004232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f21</th>\n",
       "      <td>0.004067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_hamming_m4_sorted</th>\n",
       "      <td>0.004053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f15</th>\n",
       "      <td>0.003994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vendor_Code_mean_target</th>\n",
       "      <td>0.002846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_jaro_m4_sorted</th>\n",
       "      <td>0.002751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vendor_code_pc_mean</th>\n",
       "      <td>0.002726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f23</th>\n",
       "      <td>0.002686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_n</th>\n",
       "      <td>0.002526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_hamming_m1_sorted</th>\n",
       "      <td>0.002520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_ratio_m3</th>\n",
       "      <td>0.002496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_ratio_m4_sorted</th>\n",
       "      <td>0.002446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_ratio_m1</th>\n",
       "      <td>0.002310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_ratio_m3_sorted</th>\n",
       "      <td>0.002210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_ratio_m1_sorted</th>\n",
       "      <td>0.001844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vendor_Code</th>\n",
       "      <td>0.001256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vendor_code_mean</th>\n",
       "      <td>0.001058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vendor_gl-code</th>\n",
       "      <td>0.000956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_jaro_sorted</th>\n",
       "      <td>0.000905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>str_std</th>\n",
       "      <td>0.000826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>str_kurtosis</th>\n",
       "      <td>0.000718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>str_mean</th>\n",
       "      <td>0.000687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>str_skew</th>\n",
       "      <td>0.000443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_jaro</th>\n",
       "      <td>0.000398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_ratio</th>\n",
       "      <td>0.000373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_jaro_m1</th>\n",
       "      <td>0.000363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_jaro_m2</th>\n",
       "      <td>0.000346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_jaro_m4</th>\n",
       "      <td>0.000278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_jaro_m3</th>\n",
       "      <td>0.000258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inv_Amt</th>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_distance_m4_sorted</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>str_min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_distance_m1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nunique</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_distance_m1_sorted</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_distance_m2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_distance_m2_sorted</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_distance_m3_sorted</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_distance_m4</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levenshtein_distance_m3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                importance\n",
       "f3                                0.060416\n",
       "f2                                0.048496\n",
       "f1                                0.047413\n",
       "Levenshtein_hamming_m4            0.045913\n",
       "Levenshtein_hamming_m2            0.040942\n",
       "GL_Code_pc_mean                   0.036268\n",
       "GL_Code_mean_target               0.035888\n",
       "str_sum                           0.034317\n",
       "f0                                0.033891\n",
       "GL_Code_sum                       0.033805\n",
       "GL_Code                           0.027451\n",
       "f5                                0.027293\n",
       "GL_Code_pc_sum                    0.027022\n",
       "f4                                0.026515\n",
       "Levenshtein_hamming_m1            0.026492\n",
       "GL_Code_mean                      0.026306\n",
       "Levenshtein_hamming_m3            0.025779\n",
       "n_ll                              0.023115\n",
       "f12                               0.021913\n",
       "n_l                               0.020155\n",
       "f6                                0.020041\n",
       "Levenshtein_ratio_m4              0.019150\n",
       "f10                               0.017291\n",
       "Levenshtein_hamming               0.015374\n",
       "f7                                0.014400\n",
       "f8                                0.014254\n",
       "Levenshtein_distance              0.013679\n",
       "Vendor_code_pc_sum                0.011357\n",
       "Vendor_code_sum                   0.010904\n",
       "n_ul                              0.010590\n",
       "Levenshtein_ratio_m2              0.010060\n",
       "f14                               0.009954\n",
       "f19                               0.007444\n",
       "f9                                0.006753\n",
       "f17                               0.006700\n",
       "Levenshtein_distance_sorted       0.006660\n",
       "f11                               0.006589\n",
       "str_max                           0.005957\n",
       "f18                               0.005871\n",
       "Levenshtein_jaro_m1_sorted        0.005754\n",
       "f24                               0.005473\n",
       "Levenshtein_hamming_m2_sorted     0.005399\n",
       "Levenshtein_hamming_m3_sorted     0.005353\n",
       "f16                               0.005309\n",
       "Levenshtein_jaro_m2_sorted        0.005159\n",
       "Levenshtein_ratio_m2_sorted       0.004913\n",
       "n_s                               0.004810\n",
       "f20                               0.004798\n",
       "Levenshtein_hamming_sorted        0.004641\n",
       "f22                               0.004594\n",
       "Levenshtein_jaro_m3_sorted        0.004339\n",
       "Levenshtein_ratio_sorted          0.004275\n",
       "f13                               0.004232\n",
       "f21                               0.004067\n",
       "Levenshtein_hamming_m4_sorted     0.004053\n",
       "f15                               0.003994\n",
       "Vendor_Code_mean_target           0.002846\n",
       "Levenshtein_jaro_m4_sorted        0.002751\n",
       "Vendor_code_pc_mean               0.002726\n",
       "f23                               0.002686\n",
       "n_n                               0.002526\n",
       "Levenshtein_hamming_m1_sorted     0.002520\n",
       "Levenshtein_ratio_m3              0.002496\n",
       "Levenshtein_ratio_m4_sorted       0.002446\n",
       "Levenshtein_ratio_m1              0.002310\n",
       "Levenshtein_ratio_m3_sorted       0.002210\n",
       "Levenshtein_ratio_m1_sorted       0.001844\n",
       "Vendor_Code                       0.001256\n",
       "Vendor_code_mean                  0.001058\n",
       "Vendor_gl-code                    0.000956\n",
       "Levenshtein_jaro_sorted           0.000905\n",
       "str_std                           0.000826\n",
       "str_kurtosis                      0.000718\n",
       "str_mean                          0.000687\n",
       "str_skew                          0.000443\n",
       "Levenshtein_jaro                  0.000398\n",
       "Levenshtein_ratio                 0.000373\n",
       "Levenshtein_jaro_m1               0.000363\n",
       "Levenshtein_jaro_m2               0.000346\n",
       "Levenshtein_jaro_m4               0.000278\n",
       "Levenshtein_jaro_m3               0.000258\n",
       "Inv_Amt                           0.000200\n",
       "Levenshtein_distance_m4_sorted    0.000000\n",
       "str_min                           0.000000\n",
       "Levenshtein_distance_m1           0.000000\n",
       "nunique                           0.000000\n",
       "Levenshtein_distance_m1_sorted    0.000000\n",
       "Levenshtein_distance_m2           0.000000\n",
       "Levenshtein_distance_m2_sorted    0.000000\n",
       "Levenshtein_distance_m3_sorted    0.000000\n",
       "Levenshtein_distance_m4           0.000000\n",
       "Levenshtein_distance_m3           0.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XG Boost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuning parameters of xgboost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_xgb = XGBClassifier(n_estimator = 100,seed = 42)\n",
    "# params = {\n",
    "#     'max_depth' : range(3,10,2),\n",
    "#     'min_child_weight' : range(1,6,2)\n",
    "    \n",
    "# }\n",
    "# gsearch = GridSearchCV(estimator = model_xgb, \n",
    "# param_grid = params, scoring='accuracy',n_jobs=4,iid=False, cv=5)\n",
    "# gsearch.fit(x_train,y_train)\n",
    "# gsearch.best_params_, gsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.993714 \n"
     ]
    }
   ],
   "source": [
    "#Parameters obtained from tuning above\n",
    "model_xgb = XGBClassifier(max_depth = 7, min_child_weight = 1,n_estimator = 100,seed = 42)\n",
    "model_xgb.fit(x_train,y_train)\n",
    "pred_val_xgb = model_xgb.predict(x_val)\n",
    "acc_score = accuracy_score(y_val, pred_val_xgb)\n",
    "print(\"accuracy score %f \"%acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling for linear models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_linear = scaler.fit_transform(x_train)\n",
    "x_val_linear = scaler.fit_transform(x_val)\n",
    "test_linear = scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.987876 \n"
     ]
    }
   ],
   "source": [
    "model_log = LogisticRegression(max_iter = 500,random_state=42, solver='lbfgs',multi_class='multinomial')\n",
    "model_log.fit(x_train_linear,y_train)\n",
    "pred_val_log = model_log.predict(x_val_linear)\n",
    "acc_score = accuracy_score(y_val, pred_val_log)\n",
    "print(\"accuracy score %f \"%acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.988774 \n"
     ]
    }
   ],
   "source": [
    "# params = {'C' : [1,10,100,1000],\n",
    "#           'gamma' : [1e-3,1e-4]}\n",
    "# model_svc = GridSearchCV(SVC(random_state = 42),params,cv = 5)\n",
    "# print('Best C : ',model_svc.best_estimator_.C)\n",
    "# print('Best gamma : ',model_svc.best_estimator_.gamma)\n",
    "model_svc = SVC(C = 1000,gamma = 0.001,random_state = 42)\n",
    "model_svc.fit(x_train_linear,y_train)\n",
    "pred_val_svc = model_svc.predict(x_val_linear)\n",
    "acc_score = accuracy_score(y_val, pred_val_svc)\n",
    "print(\"accuracy score %f \"%acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensembling SVM and XGB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphas_to_try = np.linspace(0, 1, 1001)\n",
    "\n",
    "# best_alpha = 0\n",
    "# best_acc = 0\n",
    "# combined = []\n",
    "# combined.append(np.c_[pred_val_svc, pred_val_xgb])\n",
    "# combined = pd.DataFrame(np.vstack(combined))\n",
    "# combined = combined.astype(np.int32)\n",
    "# y_val = y_val.astype(np.int32)\n",
    "# #print(combined)\n",
    "# for alpha in alphas_to_try:\n",
    "#     #print(alpha)\n",
    "#     mix = alpha * combined[0] + (1-alpha)*combined[1]\n",
    "#     mix = mix.astype(np.int32)\n",
    "#     acc = accuracy_score(y_val, mix)\n",
    "#     #print(acc)\n",
    "#     if best_acc < acc:\n",
    "#         best_acc = acc\n",
    "#         best_alpha = alpha\n",
    "\n",
    "\n",
    "# print('Best alpha: %f; Corresponding accuracy score on val: %f' % (best_alpha, best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_words = 2000\n",
    "# tokenizer = Tokenizer(num_words = num_words)\n",
    "# tokenizer.fit_on_texts(all_data['Item_Description'].values)\n",
    "# train_test = tokenizer.texts_to_sequences(all_data['Item_Description'].values)\n",
    "# train_test = pad_sequences(train_test, maxlen=2000)\n",
    "# train_test = np.column_stack((train_test,pd.get_dummies(all_data['GL_Code']).values))\n",
    "# train_test = np.column_stack((train_test,pd.get_dummies(all_data['Vendor_Code']).values))\n",
    "# X = train_test[:train_df.shape[0]]\n",
    "# test = train_test[train_df.shape[0]:]\n",
    "# # Build out our simple LSTM\n",
    "# embed_dim = 128\n",
    "# lstm_out = 196\n",
    "# num_class = len(train_df['Product_Category'].unique())\n",
    "# print(num_class)\n",
    "# # Model saving callback\n",
    "# ckpt_callback = ModelCheckpoint('keras_model', \n",
    "#                                  monitor='val_loss', \n",
    "#                                  verbose=1, \n",
    "#                                  save_best_only=True, \n",
    "#                                  mode='auto')\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(num_words, embed_dim, input_length = X.shape[1]))\n",
    "# model.add(LSTM(lstm_out, recurrent_dropout=0.2, dropout=0.2))\n",
    "# model.add(Dense(num_class,activation='softmax'))\n",
    "# model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['categorical_crossentropy'])\n",
    "# print(model.summary())\n",
    "# Y = pd.get_dummies(train_df['Product_Category']).values\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.4, random_state = 42)\n",
    "# print(X_train.shape, Y_train.shape)\n",
    "# print(X_test.shape, Y_test.shape)\n",
    "# batch_size = 32\n",
    "# # model.fit(X_train, Y_train, epochs=4, batch_size=batch_size, validation_split=0.2, callbacks=[ckpt_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('keras_model')\n",
    "# print(model.summary())\n",
    "# probas = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(probas.shape)\n",
    "# print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_indices = np.argmax(probas,axis = 1)\n",
    "# #print(pred_indices)\n",
    "# #print(Y_test.shape)\n",
    "# #print(pd.get_dummies(train_df['Product_Category']).dtypes)\n",
    "# classes = np.array(sorted(train_df['Product_Category'].unique()))\n",
    "# #print(classes)\n",
    "# pred_lstm = classes[pred_indices]\n",
    "# #print(pred_lstm.shape)\n",
    "# y_val = classes[np.argmax(Y_test,axis = 1)]\n",
    "# acc_score = accuracy_score(y_val, pred_lstm)\n",
    "# print(\"accuracy score %f \"%acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stacking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model_xgb\n",
    "# pred_val_bag = np.zeros(x_val.shape[0])\n",
    "# pred_test_bag = np.zeros(test.shape[0])\n",
    "# for n in range(0,bags):\n",
    "#     model.set_params(seed = seed + n)\n",
    "#     model.fit(train,target)\n",
    "#     pred_val = model.predict(x_val)\n",
    "#     pred_test = model.predict(test)\n",
    "#     pred_val_bag += pred_val\n",
    "#     pred_test_bag += pred_test\n",
    "# pred_val_bag = pred_val_bag/bags\n",
    "# pred_test_bag= pred_test_bag/bags\n",
    "# pred1 = pred_val_bag.astype(np.int32)\n",
    "# test_pred1 = pred_test_bag.astype(np.int32)\n",
    "\n",
    "# model = model_rf\n",
    "# pred_val_bag = np.zeros(x_val.shape[0])\n",
    "# pred_test_bag = np.zeros(test.shape[0])\n",
    "# for n in range(0,bags):\n",
    "#     model.set_params(random_state = seed + n)\n",
    "#     model.fit(train,target)\n",
    "#     pred_val = model.predict(x_val)\n",
    "#     pred_test = model.predict(test)\n",
    "#     pred_val_bag += pred_val\n",
    "#     pred_test_bag += pred_test\n",
    "# pred_val_bag = pred_val_bag/bags\n",
    "# pred_test_bag= pred_test_bag/bags\n",
    "# pred2 = pred_val_bag.astype(np.int32)\n",
    "# test_pred2 = pred_test_bag.astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked_predictions = np.column_stack((pred1,pred2))\n",
    "# stacked_test_predictions = np.column_stack((test_pred1,test_pred2))\n",
    "# model_svc.fit(stacked_predictions,y_val)\n",
    "# final_prediction = model_svc.predict(stacked_test_predictions)\n",
    "# best_pred = final_prediction\n",
    "# best_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Xgboost with bagging is giving me the best leaderboard score so I will keep this for final submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "model = model_xgb\n",
    "pred_test_bag = np.zeros(test.shape[0])\n",
    "for n in range(0,bags):\n",
    "    model.set_params(seed = seed + n)\n",
    "    model.fit(train,target)\n",
    "    pred_test = model.predict(test)\n",
    "    pred_test_bag += pred_test\n",
    "pred_test_bag= pred_test_bag/bags\n",
    "pred_test_bag = pred_test_bag.astype(np.int32)\n",
    "best_pred = pred_test_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = best_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ['CLASS-' + str(c) for c in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'Inv_Id':test_df['Inv_Id'],'Product_Category':pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inv_Id</th>\n",
       "      <th>Product_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15003</td>\n",
       "      <td>CLASS-1758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15008</td>\n",
       "      <td>CLASS-1522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15013</td>\n",
       "      <td>CLASS-1522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15019</td>\n",
       "      <td>CLASS-1376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15020</td>\n",
       "      <td>CLASS-1758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Inv_Id Product_Category\n",
       "0   15003       CLASS-1758\n",
       "1   15008       CLASS-1522\n",
       "2   15013       CLASS-1522\n",
       "3   15019       CLASS-1376\n",
       "4   15020       CLASS-1758"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(output_path + \"submission.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time : 525.961371 seconds\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print('Total time : %f seconds'%(end-start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
